{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "from pyproj import Transformer, CRS\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pygmt\n",
    "from sklearn.cluster import DBSCAN\n",
    "import utm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conversion functions\n",
    "\n",
    "def utm_to_latlon(x, y):\n",
    "    # Convert lat/lon to UTM coordinates\n",
    "    lat, lon = utm.to_latlon(x, y, 32, 'U')\n",
    "\n",
    "    return lat, lon\n",
    "\n",
    "def latlon_to_utm(lat, lon):\n",
    "    # Convert lat/lon to UTM coordinates\n",
    "    utm_x, utm_y, _, _ = utm.from_latlon(lat, lon)\n",
    "\n",
    "    return utm_x, utm_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# laz_file_path = \"../lasersurface/lidar_data/3dm_32_356_5645_1_nw.laz\" # Dom\n",
    "\n",
    "# laz_file_path = \"../lasersurface/lidar_data/3dm_32_358_5643_1_nw.laz\" # TÜV building in Poll\n",
    "\n",
    "laz_file_path = '/Volumes/SSD2/Split_NRW/zone_1.1/3dm_32_296_5629_1_nw.laz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with laspy.open(laz_file_path) as file:\n",
    "    las = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSFACTOR = 1 # Subsampling factor for points cloud\n",
    "\n",
    "lastReturnNichtBoden = 20\n",
    "brueckenpunkte = 17\n",
    "unclassified = 1\n",
    "\n",
    "class_ok = [brueckenpunkte, lastReturnNichtBoden, unclassified]\n",
    "\n",
    "class_val = las.classification[::SSFACTOR]\n",
    "\n",
    "mask = (np.isin(class_val, class_ok))\n",
    "\n",
    "points = np.vstack((las.x[::SSFACTOR][mask], las.y[::SSFACTOR][mask], las.z[::SSFACTOR][mask])).transpose()\n",
    "\n",
    "ground_points = las.points[las.classification == 2]\n",
    "\n",
    "gnd_points = np.vstack((ground_points.x, ground_points.y, ground_points.z)).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCG2016_geoid_file = './GCG2016_data/GCG2016_we.tif'\n",
    "#DEM_file = './DEM_data/urn_eop_DLR_CDEM10_Copernicus_DSM_04_N50_00_E006_00_V8239-2020_1__DEM1__coverage_20231204210410.tif'\n",
    "#DEM_file = '/Volumes/SSD2/Split_NRW/dgm1_32_358_5643_1_nw.tif'\n",
    "DEM_file = '/Volumes/SSD2/Split_NRW/zone_1.1_DEM/dgm1_32_296_5629_1_nw.tif'\n",
    "egm96_geoid_file = './EGM96_data/egm96_15.gtx'\n",
    "egg08_geoid_file = './EGG08_data/egm08_25.gtx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary reprojected DEM file (EPSG:28532 to EPSG:4326)\n",
    "# source: https://rasterio.readthedocs.io/en/latest/topics/reproject.html\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "dst_crs = 'EPSG:4326'\n",
    "\n",
    "with rasterio.open(DEM_file) as src:\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "\n",
    "    with rasterio.open('./temp_DEM_file.tif', 'w', **kwargs) as dst:\n",
    "        for i in range(1, src.count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(src, i),\n",
    "                destination=rasterio.band(dst, i),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=dst_crs,\n",
    "                resampling=Resampling.nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_DEM_file = './temp_DEM_file.tif'\n",
    "\n",
    "transformer = Transformer.from_pipeline(\n",
    "    f\"+proj=pipeline \"\n",
    "    f\"+step +inv +proj=utm +zone=32 +ellps=WGS84 \"  # Convert from UTM Zone 32N to geographic coordinates\n",
    "    f\"+step +proj=vgridshift +grids={temp_DEM_file} +multiplier = -1 \"  # Vertical grid shift to remove the DEM elevation\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9471722/9471722 [00:37<00:00, 252318.18it/s]\n"
     ]
    }
   ],
   "source": [
    "transformed_z = np.array([transformer.transform(xi, yi, zi)[2] for xi, yi, zi in tqdm(zip(las.x, las.y, las.z), total=9471722)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(inf, inf, inf)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.transform(356000.10000000003, 5645018.83,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.248118481420427"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_z.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test to transform only ground points and check average height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3365666/3365666 [00:13<00:00, 253146.69it/s]\n"
     ]
    }
   ],
   "source": [
    "transformed_ground_z = np.array([transformer.transform(xi, yi, zi)[2] for xi, yi, zi in tqdm(zip(ground_points.x, ground_points.y, ground_points.z), total=len(ground_points.x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.416774161873778"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_ground_z.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check DEM file values with rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "def get_dem_elevation(dem_file, lat, lon):\n",
    "    \"\"\"\n",
    "    Get the elevation from a DEM file at a given latitude and longitude.\n",
    "\n",
    "    Parameters:\n",
    "    dem_file (str): Path to the DEM file.\n",
    "    lat (float): Latitude of the point.\n",
    "    lon (float): Longitude of the point.\n",
    "\n",
    "    Returns:\n",
    "    float: Elevation at the given latitude and longitude.\n",
    "    \"\"\"\n",
    "    with rasterio.open(dem_file) as dataset:\n",
    "        # Convert the latitude and longitude to row and column\n",
    "        row, col = dataset.index(lon, lat)\n",
    "\n",
    "        print(row)\n",
    "        print(col)\n",
    "\n",
    "        row -= 5645000\n",
    "        col *= -1\n",
    "        col -= 356000\n",
    "\n",
    "        # Read the elevation at the given row and column\n",
    "        elevation = dataset.read(1)[row, col]\n",
    "        return elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:25832\n",
      "Bounds of the dataset: BoundingBox(left=356000.0, bottom=5645000.0, right=357000.0, top=5646000.0)\n"
     ]
    }
   ],
   "source": [
    "with rasterio.open(DEM_file) as dataset:\n",
    "    print(dataset.crs)\n",
    "\n",
    "    bounds = dataset.bounds\n",
    "    print(\"Bounds of the dataset:\", bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5645949\n",
      "-355994\n",
      "Elevation at (50.941276, 6.957772): 39.20750045776367 meters\n"
     ]
    }
   ],
   "source": [
    "latitude, longitude = 50.941276,6.957772\n",
    "elevation = get_dem_elevation(DEM_file, latitude, longitude)\n",
    "print(f\"Elevation at ({latitude}, {longitude}): {elevation} meters\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7983425/7983425 [00:27<00:00, 295471.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#transformed_points = np.array([transformer.transform(xi, yi, zi) for xi, yi, zi in tqdm(zip(las.x, las.y, las.z), total=len(las.x))])\n",
    "\n",
    "import os\n",
    "\n",
    "total = len(points[:,0])\n",
    "transformed_points = np.array([transformer.transform(xi, yi, zi) for xi, yi, zi in tqdm(zip(points[:,0], points[:,1], points[:,2]), total = total)])\n",
    "\n",
    "#os.remove(temp_DEM_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296008.77, 5629014.96)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[:,0][1234], points[:,1][1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the DataFrame: 244.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Create our dataframe\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"x\": points[:,0], #np.array(las.x), # We need UTM coordinates\n",
    "        \"y\": points[:,1], #np.array(las.y), # \n",
    "        \"z\": points[:,2],\n",
    "        \"h\": transformed_points[:,2]\n",
    "    }\n",
    ")\n",
    "\n",
    "size_df = sys.getsizeof(df)\n",
    "print(f\"Size of the DataFrame: {np.ceil(size_df / (1024*1024))} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 648 rows to the dataframe\n"
     ]
    }
   ],
   "source": [
    "inf_rows = df.isin([np.inf, -np.inf]).any(axis=1)\n",
    "inf_rows_df = df[inf_rows]\n",
    "df = df[~inf_rows]\n",
    "print(f'Removed {len(inf_rows_df)} rows to the dataframe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points covers region: [ 296000.  297000. 5629000. 5630000.]\n"
     ]
    }
   ],
   "source": [
    "region = pygmt.info(data=df[[\"x\", \"y\"]], spacing=1)  # West, East, South, North\n",
    "\n",
    "print(f\"Data points covers region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max, y_min, y_max = list(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed another 54588 points on the edge\n"
     ]
    }
   ],
   "source": [
    "# Filtering the DataFrame\n",
    "condition = (abs(df['x'] - x_min) < 1.5) | \\\n",
    "            (abs(df['x'] - x_max) < 1.5) | \\\n",
    "            (abs(df['y'] - y_min) < 1.5) | \\\n",
    "            (abs(df['y'] - y_max) < 1.5)\n",
    "\n",
    "df_filtered = df[~condition]\n",
    "\n",
    "# Number of rows removed\n",
    "print(f'Removed another {len(df) - len(df_filtered)} points on the edge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the DataFrame: 12.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_trimmed = pygmt.blockmedian(\n",
    "    data=df_filtered[[\"x\", \"y\", \"h\"]],\n",
    "    T=0.9999,  # 99.99th quantile, i.e. the highest point\n",
    "    spacing=\"1+e\", # 1+e for 1 m # 0.1 increases the size of df but more accurate?\n",
    "    region=region,\n",
    ")\n",
    "\n",
    "size_df_trimmed = sys.getsizeof(df_trimmed)\n",
    "print(f\"Size of the DataFrame: {np.ceil(size_df_trimmed / (1024*1024))} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v_/0jkxx12x7r9_3szb050fks9m0000gn/T/ipykernel_36787/1219368450.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high_points['cluster'] = clustering.labels_\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>h</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>296251.48</td>\n",
       "      <td>5629317.47</td>\n",
       "      <td>82.361983</td>\n",
       "      <td>0</td>\n",
       "      <td>50.779768</td>\n",
       "      <td>6.109757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x           y          h  cluster        lat       lon\n",
       "0  296251.48  5629317.47  82.361983        0  50.779768  6.109757"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify points that are above 120m above geoid (for Cologne this means about 70 m above ground).\n",
    "high_points = df_trimmed[df_trimmed['h'] > 50]\n",
    "\n",
    "# Assuming that points within 100m of each other belong to the same obstacle\n",
    "clustering = DBSCAN(eps=40, min_samples=2).fit(high_points[['x', 'y', 'h']]) # TODO: no error if no cluster found\n",
    "\n",
    "# Add the cluster labels to the high_points DataFrame\n",
    "high_points['cluster'] = clustering.labels_\n",
    "\n",
    "# Filter out noise points (DBSCAN labels noise as -1)\n",
    "obstacles = high_points[high_points['cluster'] != -1]\n",
    "\n",
    "# Find the highest point in each obstacle cluster\n",
    "highest_points = obstacles.loc[obstacles.groupby('cluster')['h'].idxmax()]\n",
    "\n",
    "# The resulting DataFrame 'highest_points' contains the coordinates of the highest point of each obstacle\n",
    "highest_points.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Apply the conversion function to the DataFrame to create new columns 'lat' and 'lon'\n",
    "highest_points['lat'], highest_points['lon'] = zip(*highest_points.apply(lambda row: utm_to_latlon(row['x'], row['y']), axis=1))\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "pd.set_option('display.max_rows', 200)\n",
    "highest_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.602780492487682"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.h.median()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the transformation steps to understand their effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer1 = Transformer.from_pipeline(\n",
    "    f\"+proj=pipeline \"\n",
    "    f\"+step +inv +proj=utm +zone=32 +ellps=WGS84 \"  # Convert from UTM Zone 32N to geographic coordinates\n",
    "    f\"+step +proj=vgridshift +grids={GCG2016_geoid_file} +multiplier = 1 \"  # Vertical grid shift to add the DHHN16 elevation -> WGS84\n",
    ")\n",
    "\n",
    "transformer2 = Transformer.from_pipeline(\n",
    "    f\"+proj=pipeline \"\n",
    "    f\"+step +inv +proj=utm +zone=32 +ellps=WGS84 \"  # Convert from UTM Zone 32N to geographic coordinates\n",
    "    f\"+step +proj=vgridshift +grids={DEM_file} +multiplier = -1 \"  # Vertical grid shift to remove the DEM elevation\n",
    ")\n",
    "\n",
    "transformer3 = Transformer.from_pipeline(\n",
    "    f\"+proj=pipeline \"\n",
    "    f\"+step +inv +proj=utm +zone=32 +ellps=WGS84 \"  # Convert from UTM Zone 32N to geographic coordinates\n",
    "    f\"+step +proj=vgridshift +grids={egg08_geoid_file} +multiplier = -1 \" # Vertical grid shift to remove the EGM2008 geoid height\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total shift: inf\n",
      "Step 1: 46.47546430129954\n",
      "Step 2: inf\n",
      "Step 3: -46.70579936854459\n"
     ]
    }
   ],
   "source": [
    "x, y = 356000.10000000003, 5645018.83\n",
    "\n",
    "print(\n",
    "    f\"Total shift: {transformer.transform(x, y,0)[2]}\\n\"\n",
    "    f\"Step 1: {transformer1.transform(x, y,0)[2]}\\n\"\n",
    "    f\"Step 2: {transformer2.transform(x, y,0)[2]}\\n\"\n",
    "    f\"Step 3: {transformer3.transform(x, y,0)[2]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525 595\n",
      "Elevation at the coordinate: 55.56\n"
     ]
    }
   ],
   "source": [
    "with rasterio.open(DEM_file) as dem:\n",
    "    # Transformer to convert UTM to geographic coordinates (WGS 84)\n",
    "    transformer = Transformer.from_crs(\"epsg:25832\", \"epsg:4326\", always_xy=True)\n",
    "\n",
    "    # UTM coordinates\n",
    "    utm_x, utm_y = 356595.8,5645474.8\n",
    "\n",
    "    # Convert UTM coordinates to row and column indices in the DEM\n",
    "    row, col = dem.index(utm_x, utm_y)\n",
    "\n",
    "    # Read the elevation value at the specified indices\n",
    "    elevation = dem.read(1)[row, col]\n",
    "\n",
    "    print(\"Elevation at the coordinate:\", elevation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new attempt with original DEM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_elev(x, y, dem_file):\n",
    "\n",
    "    with rasterio.open(dem_file) as dem:\n",
    "    # Transformer to convert UTM to geographic coordinates (WGS 84)\n",
    "\n",
    "        # Convert UTM coordinates to row and column indices in the DEM\n",
    "        row, col = dem.index(x, y)\n",
    "\n",
    "        if row==1000: row=999\n",
    "        if col==1000: col=999\n",
    "\n",
    "        #print(x, y, row, col)\n",
    "\n",
    "        # Read the elevation value at the specified indices\n",
    "        elevation = dem.read(1)[row, col]\n",
    "\n",
    "        return elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "624it [00:21, 208.55it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m z_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([find_elev(x, y, DEM_file) \u001b[39mfor\u001b[39;49;00m x, y \u001b[39min\u001b[39;49;00m tqdm(\u001b[39mzip\u001b[39;49m(points[:,\u001b[39m0\u001b[39;49m], points[:,\u001b[39m1\u001b[39;49m]))])\n",
      "Cell \u001b[0;32mIn[140], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m z_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([find_elev(x, y, DEM_file) \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m tqdm(\u001b[39mzip\u001b[39m(points[:,\u001b[39m0\u001b[39m], points[:,\u001b[39m1\u001b[39m]))])\n",
      "Cell \u001b[0;32mIn[139], line 3\u001b[0m, in \u001b[0;36mfind_elev\u001b[0;34m(x, y, dem_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_elev\u001b[39m(x, y, dem_file):\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mwith\u001b[39;00m rasterio\u001b[39m.\u001b[39;49mopen(dem_file) \u001b[39mas\u001b[39;00m dem:\n\u001b[1;32m      4\u001b[0m     \u001b[39m# Transformer to convert UTM to geographic coordinates (WGS 84)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m         \u001b[39m# Convert UTM coordinates to row and column indices in the DEM\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         row, col \u001b[39m=\u001b[39m dem\u001b[39m.\u001b[39mindex(x, y)\n\u001b[1;32m      9\u001b[0m         \u001b[39mif\u001b[39;00m row\u001b[39m==\u001b[39m\u001b[39m1000\u001b[39m: row\u001b[39m=\u001b[39m\u001b[39m999\u001b[39m\n",
      "File \u001b[0;32m~/Dev_local/Python/ValidateObstacles/.venv/lib/python3.11/site-packages/rasterio/env.py:451\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    448\u001b[0m     session \u001b[39m=\u001b[39m DummySession()\n\u001b[1;32m    450\u001b[0m \u001b[39mwith\u001b[39;00m env_ctor(session\u001b[39m=\u001b[39msession):\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/Dev_local/Python/ValidateObstacles/.venv/lib/python3.11/site-packages/rasterio/__init__.py:304\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m path \u001b[39m=\u001b[39m _parse_path(raw_dataset_path)\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     dataset \u001b[39m=\u001b[39m DatasetReader(path, driver\u001b[39m=\u001b[39;49mdriver, sharing\u001b[39m=\u001b[39;49msharing, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    305\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    306\u001b[0m     dataset \u001b[39m=\u001b[39m get_writer_for_path(path, driver\u001b[39m=\u001b[39mdriver)(\n\u001b[1;32m    307\u001b[0m         path, mode, driver\u001b[39m=\u001b[39mdriver, sharing\u001b[39m=\u001b[39msharing, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    308\u001b[0m     )\n",
      "File \u001b[0;32mrasterio/_base.pyx:312\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Dev_local/Python/ValidateObstacles/.venv/lib/python3.11/site-packages/rasterio/_path.py:113\u001b[0m, in \u001b[0;36m_UnparsedPath.name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Encapsulates legacy GDAL filenames\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39mAttributes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39m    The legacy GDAL filename.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m path \u001b[39m=\u001b[39m attr\u001b[39m.\u001b[39mib()\n\u001b[0;32m--> 113\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mname\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    115\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"The unparsed path's original path\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "z_array = np.array([find_elev(x, y, DEM_file) for x, y in tqdm(zip(points[:,0], points[:,1]))])\n",
    "\n",
    "# takes forever"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "702bde69d4ee5155b74d46a654520b5d5efccaf7a15b9a8896e2d58f0f947281"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
