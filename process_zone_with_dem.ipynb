{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "from pyproj import Transformer, CRS\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pygmt\n",
    "from sklearn.cluster import DBSCAN\n",
    "import utm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conversion functions\n",
    "\n",
    "def utm_to_latlon(x, y):\n",
    "    # Convert lat/lon to UTM coordinates\n",
    "    lat, lon = utm.to_latlon(x, y, 32, 'U')\n",
    "\n",
    "    return lat, lon\n",
    "\n",
    "def latlon_to_utm(lat, lon):\n",
    "    # Convert lat/lon to UTM coordinates\n",
    "    utm_x, utm_y, _, _ = utm.from_latlon(lat, lon)\n",
    "\n",
    "    return utm_x, utm_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "laz_file_path = \"../lasersurface/lidar_data/3dm_32_356_5645_1_nw.laz\" # Dom\n",
    "\n",
    "# laz_file_path = \"../lasersurface/lidar_data/3dm_32_358_5643_1_nw.laz\" # TÜV building in Poll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "with laspy.open(laz_file_path) as file:\n",
    "    las = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSFACTOR = 1 # Subsampling factor for points cloud\n",
    "\n",
    "lastReturnNichtBoden = 20\n",
    "brueckenpunkte = 17\n",
    "unclassified = 1\n",
    "\n",
    "class_ok = [brueckenpunkte, lastReturnNichtBoden, unclassified]\n",
    "\n",
    "class_val = las.classification[::SSFACTOR]\n",
    "\n",
    "mask = (np.isin(class_val, class_ok))\n",
    "\n",
    "points = np.vstack((las.x[::SSFACTOR][mask], las.y[::SSFACTOR][mask], las.z[::SSFACTOR][mask])).transpose()\n",
    "\n",
    "ground_points = las.points[las.classification == 2]\n",
    "\n",
    "gnd_points = np.vstack((ground_points.x, ground_points.y, ground_points.z)).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCG2016_geoid_file = './GCG2016_data/GCG2016_we.tif'\n",
    "DEM_file = './DEM_data/urn_eop_DLR_CDEM10_Copernicus_DSM_04_N50_00_E006_00_V8239-2020_1__DEM1__coverage_20231204210410.tif'\n",
    "egm96_geoid_file = './EGM96_data/egm96_15.gtx'\n",
    "egg08_geoid_file = './EGG08_data/egm08_25.gtx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer.from_pipeline(\n",
    "    f\"+proj=pipeline \"\n",
    "    f\"+step +inv +proj=utm +zone=32 +ellps=WGS84 \"  # Convert from UTM Zone 32N to geographic coordinates\n",
    "    f\"+step +proj=vgridshift +grids={GCG2016_geoid_file} +multiplier = 1 \"  # Vertical grid shift to add the DHHN16 elevation -> WGS84\n",
    "    f\"+step +proj=vgridshift +grids={DEM_file} +multiplier = -1 \"  # Vertical grid shift to remove the DEM elevation\n",
    "    f\"+step +proj=vgridshift +grids={egg08_geoid_file} +multiplier = -1 \" # Vertical grid shift to remove the EGM2008 geoid height\n",
    "    #f\"+step +proj=vgridshift +grids={egm96_geoid_file} +multiplier = 1 \" # Vertical grid shift to add the EGM96 geoid height\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9471722/9471722 [00:37<00:00, 252318.18it/s]\n"
     ]
    }
   ],
   "source": [
    "transformed_z = np.array([transformer.transform(xi, yi, zi)[2] for xi, yi, zi in tqdm(zip(las.x, las.y, las.z), total=9471722)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.957804522618755, 50.9413476698659, 144.6082798562532)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.transform(356525.6,5645288.4,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.248118481420427"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_z.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test to transform only ground points and check average height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3365666/3365666 [00:13<00:00, 253146.69it/s]\n"
     ]
    }
   ],
   "source": [
    "transformed_ground_z = np.array([transformer.transform(xi, yi, zi)[2] for xi, yi, zi in tqdm(zip(ground_points.x, ground_points.y, ground_points.z), total=len(ground_points.x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.416774161873778"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_ground_z.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check DEM file values with rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "def get_dem_elevation(dem_file, lat, lon):\n",
    "    \"\"\"\n",
    "    Get the elevation from a DEM file at a given latitude and longitude.\n",
    "\n",
    "    Parameters:\n",
    "    dem_file (str): Path to the DEM file.\n",
    "    lat (float): Latitude of the point.\n",
    "    lon (float): Longitude of the point.\n",
    "\n",
    "    Returns:\n",
    "    float: Elevation at the given latitude and longitude.\n",
    "    \"\"\"\n",
    "    with rasterio.open(dem_file) as dataset:\n",
    "        # Convert the latitude and longitude to row and column\n",
    "        row, col = dataset.index(lon, lat)\n",
    "\n",
    "        # Read the elevation at the given row and column\n",
    "        elevation = dataset.read(1)[row, col]\n",
    "        return elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevation at (50.9392718, 6.9659982): 37.0 meters\n"
     ]
    }
   ],
   "source": [
    "latitude, longitude = 50.9392718,6.9659982\n",
    "elevation = get_dem_elevation(geotiff_file, latitude, longitude)\n",
    "print(f\"Elevation at ({latitude}, {longitude}): {elevation} meters\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5614653/5614653 [00:19<00:00, 291185.27it/s]\n"
     ]
    }
   ],
   "source": [
    "#transformed_points = np.array([transformer.transform(xi, yi, zi) for xi, yi, zi in tqdm(zip(las.x, las.y, las.z), total=len(las.x))])\n",
    "\n",
    "total = len(points[:,0])\n",
    "transformed_points = np.array([transformer.transform(xi, yi, zi) for xi, yi, zi in tqdm(zip(points[:,0], points[:,1], points[:,2]), total = total)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the DataFrame: 129.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Create our dataframe\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"x\": points[:,0], #np.array(las.x), # We need UTM coordinates\n",
    "        \"y\": points[:,1], #np.array(las.y), # \n",
    "        \"z\": transformed_points[:,2]\n",
    "    }\n",
    ")\n",
    "\n",
    "size_df = sys.getsizeof(df)\n",
    "print(f\"Size of the DataFrame: {np.ceil(size_df / (1024*1024))} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points covers region: [ 356000.  357000. 5645000. 5646000.]\n"
     ]
    }
   ],
   "source": [
    "region = pygmt.info(data=df[[\"x\", \"y\"]], spacing=1)  # West, East, South, North\n",
    "\n",
    "print(f\"Data points covers region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the DataFrame: 16.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_trimmed = pygmt.blockmedian(\n",
    "    data=df[[\"x\", \"y\", \"z\"]],\n",
    "    T=0.9999,  # 99.99th quantile, i.e. the highest point\n",
    "    spacing=\"1+e\", # 1+e for 1 m # 0.1 increases the size of df but more accurate?\n",
    "    region=region,\n",
    ")\n",
    "\n",
    "size_df_trimmed = sys.getsizeof(df_trimmed)\n",
    "print(f\"Size of the DataFrame: {np.ceil(size_df_trimmed / (1024*1024))} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v_/0jkxx12x7r9_3szb050fks9m0000gn/T/ipykernel_7563/2073081422.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high_points['cluster'] = clustering.labels_\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356490.45</td>\n",
       "      <td>5645300.45</td>\n",
       "      <td>159.007408</td>\n",
       "      <td>0</td>\n",
       "      <td>50.941447</td>\n",
       "      <td>6.957300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356119.49</td>\n",
       "      <td>5645270.50</td>\n",
       "      <td>73.419708</td>\n",
       "      <td>1</td>\n",
       "      <td>50.941086</td>\n",
       "      <td>6.952035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>356149.42</td>\n",
       "      <td>5645192.48</td>\n",
       "      <td>74.105397</td>\n",
       "      <td>2</td>\n",
       "      <td>50.940392</td>\n",
       "      <td>6.952492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>356215.49</td>\n",
       "      <td>5645201.49</td>\n",
       "      <td>70.924553</td>\n",
       "      <td>3</td>\n",
       "      <td>50.940489</td>\n",
       "      <td>6.953428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x           y           z  cluster        lat       lon\n",
       "0  356490.45  5645300.45  159.007408        0  50.941447  6.957300\n",
       "1  356119.49  5645270.50   73.419708        1  50.941086  6.952035\n",
       "2  356149.42  5645192.48   74.105397        2  50.940392  6.952492\n",
       "3  356215.49  5645201.49   70.924553        3  50.940489  6.953428"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify points that are above 120m above geoid (for Cologne this means about 70 m above ground).\n",
    "high_points = df_trimmed[df_trimmed['z'] > 70]\n",
    "\n",
    "# Assuming that points within 100m of each other belong to the same obstacle\n",
    "clustering = DBSCAN(eps=50, min_samples=2).fit(high_points[['x', 'y', 'z']]) # TODO: no error if no cluster found\n",
    "\n",
    "# Add the cluster labels to the high_points DataFrame\n",
    "high_points['cluster'] = clustering.labels_\n",
    "\n",
    "# Filter out noise points (DBSCAN labels noise as -1)\n",
    "obstacles = high_points[high_points['cluster'] != -1]\n",
    "\n",
    "# Find the highest point in each obstacle cluster\n",
    "highest_points = obstacles.loc[obstacles.groupby('cluster')['z'].idxmax()]\n",
    "\n",
    "# The resulting DataFrame 'highest_points' contains the coordinates of the highest point of each obstacle\n",
    "highest_points.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Apply the conversion function to the DataFrame to create new columns 'lat' and 'lon'\n",
    "highest_points['lat'], highest_points['lon'] = zip(*highest_points.apply(lambda row: utm_to_latlon(row['x'], row['y']), axis=1))\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "pd.set_option('display.max_rows', 200)\n",
    "highest_points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the transformation steps to understand their effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer1 = Transformer.from_pipeline(\n",
    "    f\"+proj=pipeline \"\n",
    "    f\"+step +inv +proj=utm +zone=32 +ellps=WGS84 \"  # Convert from UTM Zone 32N to geographic coordinates\n",
    "    f\"+step +proj=vgridshift +grids={GCG2016_geoid_file} +multiplier = 1 \"  # Vertical grid shift to add the DHHN16 elevation -> WGS84\n",
    ")\n",
    "\n",
    "transformer2 = Transformer.from_pipeline(\n",
    "    f\"+proj=pipeline \"\n",
    "    f\"+step +inv +proj=utm +zone=32 +ellps=WGS84 \"  # Convert from UTM Zone 32N to geographic coordinates\n",
    "    f\"+step +proj=vgridshift +grids={DEM_file} +multiplier = -1 \"  # Vertical grid shift to remove the DEM elevation\n",
    ")\n",
    "\n",
    "transformer3 = Transformer.from_pipeline(\n",
    "    f\"+proj=pipeline \"\n",
    "    f\"+step +inv +proj=utm +zone=32 +ellps=WGS84 \"  # Convert from UTM Zone 32N to geographic coordinates\n",
    "    f\"+step +proj=vgridshift +grids={egg08_geoid_file} +multiplier = -1 \" # Vertical grid shift to remove the EGM2008 geoid height\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total shift: -53.29106134543536\n",
      "Step 1: 46.484095331990424\n",
      "Step 2: -53.06254837438759\n",
      "Step 3: -46.712608303038195\n"
     ]
    }
   ],
   "source": [
    "x, y = 356490.45, 5645300.45\n",
    "\n",
    "print(\n",
    "    f\"Total shift: {transformer.transform(x, y,0)[2]}\\n\"\n",
    "    f\"Step 1: {transformer1.transform(x, y,0)[2]}\\n\"\n",
    "    f\"Step 2: {transformer2.transform(x, y,0)[2]}\\n\"\n",
    "    f\"Step 3: {transformer3.transform(x, y,0)[2]}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "702bde69d4ee5155b74d46a654520b5d5efccaf7a15b9a8896e2d58f0f947281"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
