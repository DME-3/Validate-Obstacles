{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "from pyproj import Transformer, CRS\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pygmt\n",
    "from sklearn.cluster import DBSCAN\n",
    "import utm\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_files_list = \"./download_lists/zone_1.1_files.txt\"\n",
    "zone_laz_dir = \"/Volumes/SSD2/Split_NRW/zone_1.1/\"\n",
    "zone_DEM_dir = \"/Volumes/SSD2/Split_NRW/zone_1.1_DEM/\"\n",
    "\n",
    "log_dir = \"./logs/\"\n",
    "index_file = \"./assets/index.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for laz processing\n",
    "\n",
    "SSFACTOR = 1 # Subsampling factor for points cloud\n",
    "\n",
    "lastReturnNichtBoden = 20\n",
    "brueckenpunkte = 17\n",
    "unclassified = 1\n",
    "\n",
    "class_ok = [brueckenpunkte, lastReturnNichtBoden, unclassified]\n",
    "\n",
    "dst_crs = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise logging\n",
    "# Set at DEBUG if necessary\n",
    "\n",
    "logging.basicConfig(filename=f'{log_dir}/data_processing.log', \n",
    "                    level=logging.INFO, \n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_to_list(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        # Strip newline characters from each line\n",
    "        lines = [line.strip() for line in lines]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for quick lookup from the JSON data (much quicker than recursively looking up in the JSON)\n",
    "\n",
    "def create_lookup_dict(json_data):\n",
    "\n",
    "    lookup_dict = {}\n",
    "    for dataset in json_data.get('datasets', []):\n",
    "        for file in dataset.get('files', []):\n",
    "            lookup_dict[file['name']] = (file['size'], file['timestamp'])\n",
    "    return lookup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_size(filenames, lookup_dict):\n",
    "    total_files = 0\n",
    "    total_size = 0\n",
    "    not_found_files = []\n",
    "\n",
    "    for filename in filenames:\n",
    "        file_info = lookup_dict.get(filename)\n",
    "        if file_info:\n",
    "            total_files += 1\n",
    "            total_size += int(file_info[0])  # file_info[0] is the size\n",
    "        else:\n",
    "            not_found_files.append(filename)\n",
    "\n",
    "    return total_files, round(total_size / (1024**3), 2), not_found_files  # Size in GB and list of not found files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_files_exist(file_list, directory):\n",
    "    missing_files = []\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        if not os.path.exists(file_path):\n",
    "            missing_files.append(file)\n",
    "    return missing_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading necessary data and perform verifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the index file and create a lookup dictionary\n",
    "\n",
    "with open(index_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "lookup_dict = create_lookup_dict(data)\n",
    "logging.info(\"Index file loaded.\")\n",
    "\n",
    "# Load .laz files list and calculate number of files and size\n",
    "\n",
    "laz_list = load_file_to_list(zone_files_list)\n",
    "index_info = calculate_size(laz_list, lookup_dict)\n",
    "logging.info(f\"Loaded .laz file list {zone_files_list}, found {index_info[0]} files, size is {index_info[1]} GB.\")\n",
    "\n",
    "# Check that all .laz files in the list exist in the index and .laz directory\n",
    "\n",
    "if index_info[2]:\n",
    "    logging.error(f\"The following files were not found in the index: {index_info[2]}\")\n",
    "\n",
    "missing_laz = check_files_exist(laz_list, zone_laz_dir)\n",
    "\n",
    "if not missing_laz:\n",
    "    logging.info(\"All .laz files are present in the LAZ directory.\")\n",
    "else:\n",
    "    logging.error(\"The following .laz files were not found:\", missing_laz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DEM file list and perform verifications\n",
    "\n",
    "def convert_filenames(laz_files):\n",
    "    dem_files = []\n",
    "    for file in laz_files:\n",
    "        # Split the file name to extract the necessary parts\n",
    "        parts = file.split('_')\n",
    "        # Construct the new file name with the desired format\n",
    "        new_file = f\"dgm1_32_{parts[2]}_{parts[3]}_1_nw.tif\"\n",
    "        dem_files.append(new_file)\n",
    "    return dem_files\n",
    "\n",
    "dem_list = convert_filenames(laz_list)\n",
    "\n",
    "missing_DEM = check_files_exist(dem_list, zone_DEM_dir)\n",
    "\n",
    "if not missing_DEM:\n",
    "    logging.info(\"All DEM .tif files are present in the DEM directory.\")\n",
    "else:\n",
    "    logging.error(\"The following DEM .tif files were not found:\", missing_DEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dgm1_32_328_5635_1_nw.tif']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Starting to process...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for laz_file in laz_list:\n",
    "\n",
    "    laz_file_path = zone_laz_dir + laz_file\n",
    "\n",
    "    with laspy.open(laz_file_path) as file:\n",
    "        las = file.read()\n",
    "    \n",
    "    logging.debug(f\"File {laz_file} loaded\")\n",
    "\n",
    "    class_val = las.classification[::SSFACTOR]\n",
    "\n",
    "    mask = (np.isin(class_val, class_ok))\n",
    "\n",
    "    points = np.vstack((las.x[::SSFACTOR][mask], las.y[::SSFACTOR][mask], las.z[::SSFACTOR][mask])).transpose()\n",
    "\n",
    "    DEM_file = convert_filenames([laz_file])[0]\n",
    "\n",
    "    with rasterio.open(DEM_file) as src:\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({\n",
    "            'crs': dst_crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "\n",
    "        with rasterio.open('./temp_DEM_file.tif', 'w', **kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=dst_crs,\n",
    "                    resampling=Resampling.nearest)\n",
    "    \n",
    "    logging.debug(\"Saved temporary reprojected DEM file\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute execution time\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "logging.info(f\"Execution time: {execution_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
